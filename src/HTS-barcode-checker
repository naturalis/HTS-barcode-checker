#!/usr/bin/python

# Copyright (c) 2013, Naturalis Biodiversity Center and University of Applied
# Sciences Leiden. All rights reserved.
# 
# Redistribution and use in source and binary forms, with or without modification,
# are permitted provided that the following conditions are met:
# 
# *   Redistributions of source code must retain the above copyright notice, this
#     list of conditions and the following disclaimer.
# *   Redistributions in binary form must reproduce the above copyright notice,
#     this list of conditions and the following disclaimer in the documentation
#     and/or other materials provided with the distribution.
# *   Neither the name of the Naturalis Biodiversity Center, the University of
#     Applied Sciences Leiden nor the names of its contributors may be used to
#     endorse or promote products derived from this software without specific
#     prior written permission.
# 
# THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS" AND
# ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
# WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
# DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR
# ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
# (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;
# LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON
# ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
# (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
# SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.

# these are all part of the standard library
import argparse, logging, os, sys, cgi, cgitb, StringIO, csv, time, multiprocessing
from subprocess import call

# The following modules are imported from BioPython
from Bio.Blast import NCBIWWW, NCBIXML
from Bio import SeqIO
from Bio import Entrez

# CHANGE ME:
# this location contains resources used both in command line and CGI mode:
# the default databases, static HTML, javascript, images
resources = '/Library/WebServer/CGI-Executables/resources'

# here we create a simple class so we can use the same
# symbol name regardless whether it was populated from CGI or argparse
class args(object):
	pass

def print_file_contents (filename,http_header):

	# prints the contents of provided file name to stdout, possibly 
	# prefixed with an HTTP header for HTML contents
	if http_header:
		print 'Content-type: text/html'
		print
	handle = open(filename, 'r')	
	print handle.read()

# running under CGI
if os.environ.get('GATEWAY_INTERFACE') is not None:

	# enable traces to browser
	cgitb.enable()
	
	# script was called without submitting the form (which would be method="post")
	if 'GET' in os.environ['REQUEST_METHOD']:
		print_file_contents(resources + '/static.html',True)
		sys.exit(0)
	else:
		# get the CGI form object
		form = cgi.FieldStorage()

		# populate the arguments object
		args.ah = True # write as HTML
		args.o  = '-' # write to stdout
		args.ad = True # no downloading when run as CGI		
		args.ba = form.getvalue('BLAST_algorithm')
		args.bd = form.getvalue('BLAST_database')
		args.hs = int(form.getvalue('hitlist_size'))
		args.mb = ( form.getvalue('megablast') is not None )
		args.mi = int(form.getvalue('min_identity'))
		args.mc = int(form.getvalue('min_coverage'))
		args.me = float(form.getvalue('max_evalue'))
		args.cd = [ resources + '/CITES_db.csv' ]
		args.bl = resources + '/Blacklist.csv'
		args.i  = form['input_file'].file # handle to uploaded file		
		args.l  = 'critical' # be quiet	or we flood the server's error log
		args.lf = '' # no log file
	
else:
	# get the commandline arguments that specify the input fastafile and the output file
	parser = argparse.ArgumentParser(description = ('Identify a set of sequences and check if there are CITES species present'))
	parser.add_argument('-i', '--input_file', metavar='fasta file', dest='i', type=str, 
				help='input data in FASTA format', default='', required=True)
	parser.add_argument('-o', '--output_file', metavar='output file', dest='o', type=str, 
				help='results file in CSV format. if "-" is provided, output is to STDOUT', default='-')
	parser.add_argument('-ba', '--BLAST_algorithm', metavar='algorithm', dest='ba', type=str, 
				help='BLAST algorithm to use (optional, default=blastn)', default='blastn')
	parser.add_argument('-bd', '--BLAST_database', metavar='database', dest='bd', type=str,
				help = 'BLAST database to use (optional, default=nt)', default = 'nt')
	parser.add_argument('-hs', '--hitlist_size', dest='hs', type=int,
				help = 'number of results BLAST wil return (optional, default=10)', default = 10)
	parser.add_argument('-mb', '--megablast', dest='mb', action='store_true', 
				help = 'use megablast, can only be used in combination with blastn (optional)')
	parser.add_argument('-mi', '--min_identity', dest='mi', type=int, 
				help = 'lowest percentage identity for BLAST results to consider (optional, default=97)', default = 97)
	parser.add_argument('-mc', '--min_coverage', dest='mc', type=int, 
				help = 'minimal coverage for BLAST results in number of bases (optional, default=100)', default = 100)
	parser.add_argument('-me', '--max_evalue', dest='me', type=float, 
				help = 'threshold E-value for BLAST results (optional, default=0.05)', default = 0.05)
	parser.add_argument('-bl', '--blacklist', metavar='blacklist file', dest='bl', type=str, action='append',
				help = 'CSV file containing blacklisted genbank accession numbers (optional)', nargs='+') 
	parser.add_argument('-cd', '--CITES_db', metavar='CITES database file', dest='cd', type=str, action='append',
				help = 'one or more database (CSV) files with CITES-listed taxon identifiers', required=True, nargs='+')
	parser.add_argument('-fd', '--force_download', dest='fd', action='store_true',
				help = 'force update of the local CITES database (optional)')
	parser.add_argument('-ad', '--avoid_download', dest='ad', action='store_true',
				help = 'avoid updating the local CITES database (optional)')
	parser.add_argument('-ah', '--as_html', dest='ah', action='store_true', default = False,
				help = 'format output as HTML')
	parser.add_argument('-l', '--logging', metavar='log level', dest='l', type=str,
				help = 'set log level to: debug, info, warning (default) or critical', default='warning')
	parser.add_argument('-lf', '--log_file', metavar='log file', dest='lf', type=str,
				help = 'specifies a file to log to. if unset, logging is to STDERR', default='')
	args = parser.parse_args()


def sanitize_multiple_inputs(input_list):

	# remove list nesting on multiple input files
	if type(input_list[0]) == list:
		if len(input_list) > 1:
			return [item[0] for item in input_list]
		else:
			return input_list[0]
	else:
		return input_list


def get_blacklist ():
	
	# return a list containing the blacklisted genbank id's
	# the blacklist follows the following format:
	# genbank_id, description
	logging.debug('Trying to obtain genbank IDs from blacklist file: %s.' % args.bl)
	try:
		final_blacklist = []
		for blacklist_file in args.bl:		
			final_blacklist += [line.split(',')[0].split('.')[0] for line in open(blacklist_file,'r') if line[0] != '#']
		return list(set(final_blacklist))
	except:
		return []


def get_CITES ():
	
	# Open the Retrieve_CITES.py script to either check the status of the
	# user provided CITES database or obtain a new copy of the database

	logging.debug('Getting path to Retrieve_CITES.py script.')
	dir, file = os.path.split(os.path.realpath(sys.argv[0]))
	CITES_path = dir + '/Retrieve_CITES.py'
	logging.debug('Retrieve_CITES.py path set to: %s.' % CITES_path)

	if args.fd == True:
		path = call([CITES_path, '-db'] + args.cd + ['-f', '-l', args.l, '-lf', args.lf])
	else:
		path = call([CITES_path, '-db'] + args.cd + ['-l', args.l, '-lf', args.lf])


def get_CITES_dic ():
	
	# open the local CITES database, return a dictionary
	# containing the CITES information with the taxids as keys
	
	logging.debug('Parsing through list of CITES dictionaries.')

	CITES_dic = {}
	for path in args.cd:
		logging.debug('Reading CITES information from file: %s.' % path)
		with open(path, 'rb') as csvfile:
			reader = csv.reader(csvfile)		
			for line in reader:
				if line[0] != 'Date' and line[0][0] != '#':
					CITES_dic[line[0]] = line[1:]

	return CITES_dic


def blast_bulk (sequences, thread_number):

	# create the list where all the blast results are stored in
	blast_list = []

	# fill the temp file with sequences
	logging.debug('Writing fasta sequences to temporary in-memory file.')
	temp = StringIO.StringIO()
	SeqIO.write(sequences, temp, 'fasta')	
	temp.seek(0,0) # rewind so that read() starts at top

	# blast the temporary file, and save the blasthits in the blast_list
	logging.debug('Blasting fasta sequences.')
	try:	
		result_handle = NCBIWWW.qblast(args.ba, args.bd, temp.read(), megablast=args.mb, hitlist_size=args.hs)
		logging.debug('Parsing blast result XML file.')
		blast_list += [item for item in NCBIXML.parse(result_handle)]
	except:
		logging.warning('Failed to obtain blast results.')		
		return 'failed'

	# return the filled blast hit
	return blast_list


def parse_blast_align (sequences, thread, CITES_dic, blacklist):

	# try to blast the sequences and obtain the results

	blast_count, blast_list = 0, 'failed'
	while blast_list == 'failed' and blast_count < 3:
		blast_list = blast_bulk(sequences, thread)
		blast_count += 1
		logging.info('Blast thread: %i failed, retrying attempt %i.' % (thread, blast_count))

	if blast_list == 'failed':
		logging.debug('Could not obtain blast hits for set of sequences, written to output file as \"failed\".')
		for seq in sequences:
			write_results([seq.description, 'failed'], 'a', 'td', False)
		return

	count, taxa_for_query, cites_for_query = 1, {}, {}

	# parse though the blast hits
	logging.debug('Parsing through blast XML results.')
	for blast_result in blast_list:
		for alignment in blast_result.alignments:
			for hsp in alignment.hsps:
				            		
				# calculate the %identity
				identity = float(hsp.identities/(len(hsp.match)*0.01))

				# grab the genbank number
				gb_num = alignment.title.split('|')[1:4:2]
				gb_num[1] = gb_num[1].split('.')[0]

				# an alignment needs to meet 3 criteria before 
				# it is an acceptable result: above the minimum 
				# identity, minimum coverage and E-value
			
				# create containing the relevant blast results
				# pass this list to the filter_hits function to
				# filter and write the blast results
				filter_hits([blast_result.query, alignment.title, gb_num, str(identity),
					str(blast_result.query_length), str(hsp.expect), str(hsp.bits)], 
					CITES_dic, blacklist, taxa_for_query, cites_for_query)
				count += 1
	
	# here we report whether a sequence has multiple taxa
	for sequence in taxa_for_query.keys():
		totalN = len(taxa_for_query[sequence])
		citesN = len(cites_for_query[sequence])
		if totalN > 1 and citesN > 1:
			logging.info('{} out of a total of {} distinct taxa for {} are CITES-listed'.format(citesN,totalN,sequence))


def filter_hits (blast, CITES_dic, blacklist, taxa_for_query, cites_for_query):
	
	# filter the blast hits, based on the minimum
	# identity, minimum coverage, e-value and the user blacklist
	if float(blast[3]) >= args.mi and int(blast[4]) >= args.mc and float(blast[5]) <= args.me:
		if blast[2][0] not in blacklist and blast[2][1] not in blacklist:
			taxon = obtain_tax(blast[2][0])
			blast[2] = blast[2][0]
			results, flag_cites = blast+taxon, False

			# grow the list of taxa associated with a single sequence
			if blast[0] not in taxa_for_query:
				taxa_for_query[blast[0]] = set()
			taxa_for_query[blast[0]].add(taxon[0])
			
			if blast[0] not in cites_for_query:
				cites_for_query[blast[0]] = set()

			# check if the taxon id of the blast hit
			# is present in the CITES_dic
			if taxon[0] in CITES_dic:
				logging.debug('Appending CITES info to blast hit.')
				results += CITES_dic[taxon[0]][1:]				
				cites_for_query[blast[0]].add(taxon[0])
				flag_cites = True
			else:
				results += ['','','']
			
			# write the results
			write_results(results, 'a', 'td', flag_cites)

	
def obtain_tax (code):
	
	# try to obtain the taxon id
	taxon = ''

	try:
		# based on the genbank id the taxon id is retrieved from genbank
		Entrez.email = "HTS-barcode-checker@gmail.com"
		handle = Entrez.efetch(db="nucleotide", id= code, rettype="gb",retmode="text")
		record = SeqIO.read(handle, "gb")

		# parse through the features and grap the taxon_id
		sub = record.features
		taxon = sub[0].qualifiers['db_xref'][0].split(':')[1]
		species = sub[0].qualifiers['organism'][0]

	except:
		logging.warning('Could not obtain a taxon info for taxon ID: %s.' % code)
		taxon, species = 'unknown ID', 'unknown species'

	return [taxon, species]


def write_results (result, mode, tag, flag_cites):

	# ignore empty strings!
	if result != '':
	
		# format the result, either as html table row or as CSV row
		formatted = ''
		if args.ah:
		
			# create HTML table row
			formatted = '\t\t\t<tr'
			if flag_cites:
				formatted += ' class="cites"'
			formatted += '>\n'
			for i, item in enumerate(result):
				ncbi = 'http://ncbi.nlm.nih.gov/'
				
				# make clickable link to hit record
				if i == 2 and tag != 'th':
					item = '<a href="{}nuccore/{}">{}</a>'.format(ncbi,item,item)
					
				# make clickable link to taxonomy record
				if i == 7 and tag != 'th':
					item = '<a href="{}taxonomy/{}">{}</a>'.format(ncbi,item,item)
				template = '\t\t\t\t<{} class="col{}">{}</{}>\n'
				formatted += template.format(tag,i,item,tag)
			formatted += '\t\t\t</tr>\n'
			
			# write the results to stdout
			if args.o == '-':
				print(formatted + '\n')
	
			# write the results to the output file
			else:
				out_file = open(args.o, mode)
				out_file.write(formatted + '\n')
				out_file.close()			
			
		else:
			csvfile = sys.stdout
			if args.o != '-':
				csvfile = open(args.o, mode)
			writer = csv.writer(csvfile)
			writer.writerow(result)
	



def parse_seq_file (CITES_dic, blacklist):

	# parse the fasta file
	logging.info('Reading user provided fasta file: %s.' % args.i)
	seq_list, sub_list = [seq for seq in SeqIO.parse(args.i, 'fasta')], []
	
	# blast each sequence in the seq_list list
	procs, count, threads = [], 1, 10
	logging.info('Blasting sequences, total: %i.' % len(seq_list))
	logging.debug('Start multithreaded blast search.')
	while len(seq_list) > 0 or len(procs) > 0:
		# start the maximum number of threads
		while len(procs) < threads and len(seq_list) > 0:
			if len(seq_list) >= 50:
				sub_list = seq_list[:50]
				seq_list = seq_list[50:]
			else:
				sub_list = seq_list
				seq_list = []
			logging.debug('Try to open a blast thread.')
			try:
				logging.debug('Opening thread number: %i, total number %i.' % (len(procs), count))
				p = multiprocessing.Process(target=parse_blast_align, args=(sub_list, count, CITES_dic, blacklist,)) 
				procs.append([p, time.time()])
				p.start()
				count+=1
			except:
				logging.warning('Failed to open thread number: %i, total number %i.' % (len(procs), count))
				break

		# check when a thread is done, remove from the thread list and start
		# a new thread
		while len(procs) > 0:
			for p in procs:
				if p[0].is_alive() == False:
					logging.debug('Process %s finished.' % str(p[0]))
					p[0].join()
					procs.remove(p)
				# time-out after 30 minutes
				elif time.time() - p[1] > 10800:
					try:
						logging.warning('Timeout for process %s.' % str(p[0]))
					except:
						pass
					logging.debug('Terminating and removing process %s.' % str(p[0]))
					p[0].terminate()
					procs.remove(p)
			break


def main ():

	# configure logging
	log_level  = getattr(logging, args.l.upper(), None)
	log_format = '%(funcName)s [%(lineno)d]: %(levelname)s: %(message)s'
	if not isinstance(log_level, int):
		raise ValueError('Invalid log level: %s' % loglevel)
		return	
	if args.lf == '':
		logging.basicConfig(format=log_format, level=log_level)
	else:
		logging.basicConfig(filename=args.lf, filemode='a', format=log_format, level=log_level)

	# Write input commands to log
	logging.debug(' '.join(sys.argv))

	# clean CITES lists and blacklist if applicable
	args.cd = sanitize_multiple_inputs(args.cd)
	if args.bl != None:
		args.bl = sanitize_multiple_inputs(args.bl)
	
	# Check if input fasta file and output file are provided
	if args.i == '':
		logging.critical('No fasta file or output file provided, see -help for details.')
		return

	# Check if there is a more recent CITES list online
	if args.ad != True:
		logging.info('Checking the status of the current CITES database.')
		get_CITES()

	# create a dictionary containing the local CITES set	
	logging.info('Reading the CITES database(s) from {}'.format(args.cd))
	CITES_dic = get_CITES_dic()

	# create a list with the blacklisted genbank ids
	logging.info('Reading the user Taxon ID blacklist.')
	blacklist = get_blacklist()

	# create a blank result file and write the header
	if args.ah:
		print_file_contents(resources + '/header.html',True)
	header = [ 
		'Query ID',
		'Hit description',
		'GI',
		'% identity',
		'Hit length',
		'E-value',
		'Bit score',
		'Taxon ID',
		'Species name',
		'CITES info (numbers match the footnotes at the online CITES appendice)',
		'NCBI taxon name',
		'CITES appendix' 
	]
	write_results(header, 'w', 'th', False)

	# parse through the sequence file, blast all sequences and write the blast hits + CITES info
	logging.info('Processing the sequence file.')
	parse_seq_file(CITES_dic, blacklist)
	
	# write the HTML footer, if needed
	if args.ah:
		print_file_contents(resources + '/footer.html',False)

	logging.critical('Done. Results are written to the: ' + args.o + ' output file')


if __name__ == "__main__":
    main()

